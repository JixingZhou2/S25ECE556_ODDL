{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0arbqcs8_Vt",
        "outputId": "27b6115d-4ed2-42d8-ade1-6a92aac1b345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "hALHipAQ8yxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3B0uRb9k7qB"
      },
      "source": [
        "Original weights Valid and Test eval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSpJ6hfJl8iU",
        "outputId": "84d14f5a-a812-471e-e0af-a2bf132624f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load your trained model\n",
        "weights = \"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_s11.pt\"\n",
        "model = YOLO(weights)\n",
        "\n",
        "data_yaml = \"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/data.yaml\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Move model to device (GPU recommended)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "print(f\"Model device: {model.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cskvM2Wqjm7U"
      },
      "source": [
        "# Original model evaluation (before pruning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovWpM1feejTX",
        "outputId": "23c7b8dd-db86-46ac-ee4f-149b9917f59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.2±0.1 ms, read: 22.1±5.5 MB/s, size: 29.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/valid/labels.cache... 90 images, 0 backgrounds, 0 corrupt: 100%|██████████| 90/90 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:02<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         90         93      0.921      0.923      0.951      0.784      0.525      0.502      0.371      0.127\n",
            "            half-squat         15         16      0.927      0.791      0.899      0.736      0.604        0.5      0.397     0.0977\n",
            "                 plank         38         38       0.99          1      0.995      0.846       0.94      0.947      0.895       0.37\n",
            "                 squat         18         20      0.878        0.9      0.927      0.777      0.367       0.35       0.15     0.0297\n",
            "                 stand         19         19      0.889          1      0.982      0.775      0.188      0.211     0.0432     0.0114\n",
            "Speed: 2.4ms preprocess, 4.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/val3\u001b[0m\n",
            "Validation mAP50: 0.7836\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 31.6±3.9 MB/s, size: 32.7 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/test/labels.cache... 48 images, 0 backgrounds, 0 corrupt: 100%|██████████| 48/48 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         48         48      0.805       0.87      0.796      0.689      0.462      0.511      0.367      0.129\n",
            "            half-squat          3          3      0.494      0.655      0.409       0.37      0.481      0.629      0.333     0.0889\n",
            "                 plank         22         22       0.98          1      0.995      0.863      0.892      0.909       0.87      0.377\n",
            "                 squat         12         12      0.785      0.917      0.819      0.638      0.379      0.417       0.25     0.0452\n",
            "                 stand         11         11      0.962      0.909       0.96      0.883     0.0966     0.0909     0.0159    0.00319\n",
            "Speed: 3.0ms preprocess, 4.6ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/val4\u001b[0m\n",
            "Test mAP50: 0.6886\n"
          ]
        }
      ],
      "source": [
        "results = model.val(data=data_yaml, split=\"val\")  # Change dataset.yaml path if needed\n",
        "print(f\"Validation mAP50: {results.box.map:.4f}\")\n",
        "\n",
        "results = model.val(data=data_yaml, split=\"test\")  # For test set evaluation\n",
        "print(f\"Test mAP50: {results.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb9us5ynfeQO"
      },
      "source": [
        "# Pruning 1\n",
        "L1 Norm unstrcuted pruning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "from ultralytics import YOLO\n",
        "import copy\n",
        "\n",
        "# Load base model\n",
        "base_model = YOLO(\"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_s11.pt\")\n",
        "model = base_model.model\n",
        "baseline_metrics = base_model.val(data=data_yaml, verbose=False)\n",
        "baseline_map50 = baseline_metrics.box.map50\n",
        "print(f\"\\nBaseline mAP50: {baseline_map50:.4f}\")\n",
        "\n",
        "prune_ratio = 0.8\n",
        "blocks_to_check = [2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22]\n",
        "target_layers = [\"cv1.conv\", \"cv2.conv\", \"cv3.conv\"]  # Top-level convs\n",
        "sensitivity_results = []\n",
        "\n",
        "for i in blocks_to_check:\n",
        "    block = model.model[i]\n",
        "\n",
        "    for name in target_layers:\n",
        "        # Split nested attributes: e.g., \"cv1.conv\"\n",
        "        parts = name.split('.')\n",
        "        sub = block\n",
        "        for p in parts:\n",
        "            sub = getattr(sub, p, None)\n",
        "            if sub is None:\n",
        "                break\n",
        "\n",
        "        if isinstance(sub, nn.Conv2d):\n",
        "            conv = sub\n",
        "            print(f\"Pruning: Block {i}, Layer {name}\")\n",
        "\n",
        "            # Backup\n",
        "            original_weight = conv.weight.data.clone()\n",
        "\n",
        "            # Prune\n",
        "            prune.l1_unstructured(conv, name=\"weight\", amount=prune_ratio)\n",
        "\n",
        "            # Evaluate\n",
        "            temp_model = copy.deepcopy(base_model)\n",
        "            temp_model.model.model[i] = block\n",
        "            metrics = temp_model.val(data=data_yaml, verbose=False)\n",
        "            pruned_map50 = metrics.box.map50\n",
        "            drop = baseline_map50 - pruned_map50\n",
        "            sensitivity_results.append((f\"Block {i} - {name}\", round(drop, 4)))\n",
        "\n",
        "            # Restore\n",
        "            conv.weight.data.copy_(original_weight)\n",
        "            prune.remove(conv, 'weight')\n",
        "        else:\n",
        "            print(f\"Skipped: Block {i}, Layer {name} not found or not Conv2d\")\n",
        "\n",
        "# Sort and show results\n",
        "sensitivity_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nLayer-wise Sensitivity Summary (Sorted by drop in mAP50):\")\n",
        "for layer, drop in sensitivity_results:\n",
        "    print(f\"{layer}: mAP50 drop = {drop:.4f}\")\n"
      ],
      "metadata": {
        "id": "sWEjb2mifehS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm available layers per block\n",
        "for i in range(len(model.model)):\n",
        "    block = model.model[i]\n",
        "    print(f\"\\nBlock {i}: {type(block)}\")\n",
        "    for name, submodule in block.named_modules():\n",
        "        print(f\"  {name}: {type(submodule)}\")\n"
      ],
      "metadata": {
        "id": "j7k1vWlhgcGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import copy\n",
        "\n",
        "# Backup original model for comparison\n",
        "original_model = copy.deepcopy(model)\n",
        "prune_ratio_high = 0.63  # Set pruning amount\n",
        "prune_ratio_low = 0.5\n",
        "numbers_to_check = range(1, 23)  # Blocks to focus pruning on\n",
        "masks = {}  # Dictionary to store pruning masks\n",
        "\n",
        "# Layers we want to prune (safely)\n",
        "target_layer_keywords = [\"cv1.conv\", \"cv2.conv\", \"cv3.conv\", \"cv4.conv\", \"cv5.conv\",\n",
        "    \"stem.conv\", \"conv\"]\n",
        "\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        # Skip pose head\n",
        "        if \"head\" in name or \"pose\" in name:\n",
        "            continue\n",
        "\n",
        "        for num in numbers_to_check:\n",
        "            if any(k in name for k in target_layer_keywords) and f\".{num}.\" in name:\n",
        "                match num:\n",
        "                    case 1:\n",
        "                        prune_ratio = 0\n",
        "                    case 2:\n",
        "                        prune_ratio = 0.65\n",
        "                    case 3:\n",
        "                        prune_ratio = 0\n",
        "                    case 4:\n",
        "                        prune_ratio = 0.65\n",
        "                    case 5:\n",
        "                        prune_ratio = 0\n",
        "                    case 6:\n",
        "                        prune_ratio = 0.65\n",
        "                    case 7:\n",
        "                        prune_ratio = 0\n",
        "                    case 8:\n",
        "                        prune_ratio = 0.65\n",
        "                    case 9:\n",
        "                        prune_ratio = 0.65\n",
        "                    case 10:\n",
        "                        prune_ratio = 0.55\n",
        "                    case 11:\n",
        "                        prune_ratio = 0\n",
        "                    case 12:\n",
        "                        prune_ratio = 0\n",
        "                    case 13:\n",
        "                        prune_ratio = 0.55\n",
        "                    case 14:\n",
        "                        prune_ratio = 0\n",
        "                    case 15:\n",
        "                        prune_ratio = 0\n",
        "                    case 16:\n",
        "                        prune_ratio = 0.5\n",
        "                    case 17:\n",
        "                        prune_ratio = 0.1\n",
        "                    case 18:\n",
        "                        prune_ratio = 0.1\n",
        "                    case 19:\n",
        "                        prune_ratio = 0.4\n",
        "                    case 20:\n",
        "                        prune_ratio = 0.1\n",
        "                    case 21:\n",
        "                        prune_ratio = 0.1\n",
        "                    case 22:\n",
        "                        prune_ratio = 0.4\n",
        "\n",
        "                print(f\"Pruning layer (ratio={prune_ratio}): {name}\")\n",
        "\n",
        "                # Apply pruning\n",
        "                prune.l1_unstructured(module, name='weight', amount=prune_ratio)\n",
        "\n",
        "                # Store the mask\n",
        "                mask_name = name + '.weight_mask'\n",
        "                weight_mask = dict(module.named_buffers()).get('weight_mask', None)\n",
        "                if weight_mask is not None:\n",
        "                    masks[name + '.weight'] = weight_mask.clone()\n",
        "                # Remove reparam\n",
        "                prune.remove(module, 'weight')\n",
        "\n",
        "                break\n",
        "\n",
        "            # Store the mask\n",
        "            weight_mask = dict(module.named_buffers()).get('weight_mask', None)\n",
        "            if weight_mask is not None:\n",
        "                masks[name + '.weight'] = weight_mask.clone()\n",
        "                prune.remove(module, 'weight')  # 只有剪枝过的才 remove\n",
        "\n",
        "\n",
        "\n",
        "# Save the entire pruned model\n",
        "output_dir = \"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models\"\n",
        "model.save(f\"{output_dir}/best_pruned_s11.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkhYCPLDKLrj",
        "outputId": "1682e0d7-4b97-4753-8ea0-bfd4c5d79fd3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruning layer (ratio=0): model.model.1.conv\n",
            "Pruning layer (ratio=0.65): model.model.2.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.2.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.2.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.2.m.0.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.3.conv\n",
            "Pruning layer (ratio=0.65): model.model.4.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.4.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.4.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.4.m.0.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.5.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.m.0.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.m.0.cv3.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.m.0.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.6.m.0.m.0.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.6.m.0.m.1.cv1.conv\n",
            "Pruning layer (ratio=0): model.model.6.m.0.m.1.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.7.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.m.0.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.m.0.cv3.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.m.0.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.8.m.0.m.0.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.8.m.0.m.1.cv1.conv\n",
            "Pruning layer (ratio=0): model.model.8.m.0.m.1.cv2.conv\n",
            "Pruning layer (ratio=0.65): model.model.9.cv1.conv\n",
            "Pruning layer (ratio=0.65): model.model.9.cv2.conv\n",
            "Pruning layer (ratio=0.55): model.model.10.cv1.conv\n",
            "Pruning layer (ratio=0.55): model.model.10.cv2.conv\n",
            "Pruning layer (ratio=0.55): model.model.10.m.0.attn.qkv.conv\n",
            "Pruning layer (ratio=0.55): model.model.10.m.0.attn.proj.conv\n",
            "Pruning layer (ratio=0.55): model.model.10.m.0.attn.pe.conv\n",
            "Pruning layer (ratio=0.55): model.model.10.m.0.ffn.0.conv\n",
            "Pruning layer (ratio=0): model.model.10.m.0.ffn.1.conv\n",
            "Pruning layer (ratio=0.55): model.model.13.cv1.conv\n",
            "Pruning layer (ratio=0.55): model.model.13.cv2.conv\n",
            "Pruning layer (ratio=0.55): model.model.13.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.55): model.model.13.m.0.cv2.conv\n",
            "Pruning layer (ratio=0.5): model.model.16.cv1.conv\n",
            "Pruning layer (ratio=0.5): model.model.16.cv2.conv\n",
            "Pruning layer (ratio=0.5): model.model.16.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.5): model.model.16.m.0.cv2.conv\n",
            "Pruning layer (ratio=0.1): model.model.17.conv\n",
            "Pruning layer (ratio=0.4): model.model.19.cv1.conv\n",
            "Pruning layer (ratio=0.4): model.model.19.cv2.conv\n",
            "Pruning layer (ratio=0.4): model.model.19.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.4): model.model.19.m.0.cv2.conv\n",
            "Pruning layer (ratio=0.1): model.model.20.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.cv1.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.cv2.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.m.0.cv2.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.m.0.cv3.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.m.0.m.0.cv1.conv\n",
            "Pruning layer (ratio=0.4): model.model.22.m.0.m.0.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.22.m.0.m.1.cv1.conv\n",
            "Pruning layer (ratio=0): model.model.22.m.0.m.1.cv2.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv2.0.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv2.1.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv2.1.1.conv\n",
            "Pruning layer (ratio=0.65): model.model.23.cv2.2.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv2.2.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.0.0.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.0.1.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.0.1.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.1.0.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.1.0.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.1.1.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.1.1.1.conv\n",
            "Pruning layer (ratio=0.65): model.model.23.cv3.2.0.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.2.0.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.2.1.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv3.2.1.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv4.0.1.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv4.1.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv4.1.1.conv\n",
            "Pruning layer (ratio=0.65): model.model.23.cv4.2.0.conv\n",
            "Pruning layer (ratio=0): model.model.23.cv4.2.1.conv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58itQC89kiTK"
      },
      "source": [
        "#Pruned model test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-EeYK24d4hl",
        "outputId": "b985527a-75f9-40f8-af07-d7039e95f617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruned model successfully loaded for evaluation!\n",
            "YOLO11s-pose summary (fused): 109 layers, 9,971,979 parameters, 0 gradients, 23.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 22.6±6.8 MB/s, size: 33.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/valid/labels.cache... 90 images, 0 backgrounds, 0 corrupt: 100%|██████████| 90/90 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:02<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         90         93      0.677      0.639      0.646      0.453      0.255      0.177      0.126     0.0163\n",
            "            half-squat         15         16      0.819      0.849      0.831      0.595      0.222      0.188     0.0696     0.0101\n",
            "                 plank         38         38      0.792      0.602      0.748      0.508       0.62      0.368      0.359      0.046\n",
            "                 squat         18         20      0.521        0.6      0.553      0.397      0.108        0.1     0.0215    0.00366\n",
            "                 stand         19         19      0.577      0.503      0.453      0.313     0.0705     0.0526     0.0551    0.00551\n",
            "Speed: 2.4ms preprocess, 4.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/val3\u001b[0m\n",
            "Validation mAP50: 0.4533\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 18.7±3.6 MB/s, size: 29.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/test/labels.cache... 48 images, 0 backgrounds, 0 corrupt: 100%|██████████| 48/48 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         48         48      0.725      0.734      0.755      0.579      0.248      0.199      0.133      0.017\n",
            "            half-squat          3          3      0.328      0.654      0.544      0.345          0          0          0          0\n",
            "                 plank         22         22      0.948      0.636      0.776      0.567      0.786      0.545      0.459     0.0585\n",
            "                 squat         12         12      0.766      0.917      0.852      0.708      0.207       0.25     0.0717    0.00963\n",
            "                 stand         11         11      0.858      0.727      0.846      0.695          0          0          0          0\n",
            "Speed: 2.9ms preprocess, 4.6ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/pose/val4\u001b[0m\n",
            "Test mAP50: 0.5786\n"
          ]
        }
      ],
      "source": [
        "# Load the FULL pruned model instead of just state_dict\n",
        "model1 = YOLO(\"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.pt\")\n",
        "\n",
        "# Move to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model1.to(device)\n",
        "\n",
        "print(\"Pruned model successfully loaded for evaluation!\")\n",
        "\n",
        "results = model1.val(data=data_yaml, split=\"val\")  # Change dataset.yaml path if needed\n",
        "print(f\"Validation mAP50: {results.box.map:.4f}\")\n",
        "\n",
        "results = model1.val(data=data_yaml, split=\"test\")  # For test set evaluation\n",
        "print(f\"Test mAP50: {results.box.map:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def compute_global_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d) and hasattr(module, \"weight\"):\n",
        "            weight = module.weight.data\n",
        "            total_params += weight.numel()\n",
        "            zero_params += torch.sum(weight == 0).item()\n",
        "\n",
        "    sparsity = 100.0 * zero_params / total_params if total_params > 0 else 0\n",
        "    print(f\"Global Sparsity: {sparsity:.2f}% ({zero_params}/{total_params})\")\n",
        "\n",
        "\n",
        "compute_global_sparsity(model.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoG7NslnUkQk",
        "outputId": "befd75e7-b501-4a12-c04b-fc45e33560a4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Sparsity: 32.40% (3226171/9956270)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Quantization: Export ONNX into FP16"
      ],
      "metadata": {
        "id": "uz0ADzIWv16_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your trained YOLOv8 model (e.g., YOLOv8n/y/m/l or a custom model)\n",
        "model = YOLO(\"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.pt\")\n",
        "\n",
        "# Move model to device (GPU recommended)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "print(f\"Model device: {model.device}\")\n",
        "\n",
        "# Export to ONNX quantization\n",
        "model.export(format=\"onnx\", dynamic=True, half=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "0YPE7xtiobjr",
        "outputId": "0e66140d-f8d6-45ef-f391-fe0ca42c9da7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model device: cuda:0\n",
            "Ultralytics 8.3.125 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "WARNING ⚠️ half=True only compatible with GPU export, i.e. use device=0\n",
            "YOLO11s-pose summary (fused): 109 layers, 9,971,979 parameters, 0 gradients, 23.3 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 65, 8400) (19.4 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.46', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxslim>=0.1.46\n",
            "  Downloading onnxslim-0.1.51-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.12.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim>=0.1.46) (1.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim>=0.1.46) (24.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim>=0.1.46) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 289.0 MB/s eta 0:00:00\n",
            "Downloading onnxslim-0.1.51-py3-none-any.whl (145 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 145.6/145.6 kB 306.1 MB/s eta 0:00:00\n",
            "Downloading onnxruntime_gpu-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.8/280.8 MB 358.6 MB/s eta 0:00:00\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 246.0 MB/s eta 0:00:00\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 303.5 MB/s eta 0:00:00\n",
            "Installing collected packages: onnx, humanfriendly, onnxslim, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-gpu-1.21.1 onnxslim-0.1.51\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 12.5s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim>=0.1.46', 'onnxruntime-gpu']\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.51...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 33.6s, saved as '/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.onnx' (38.2 MB)\n",
            "\n",
            "Export complete (35.8s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models\u001b[0m\n",
            "Predict:         yolo predict task=pose model=/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.onnx imgsz=640  \n",
            "Validate:        yolo val task=pose model=/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.onnx imgsz=640 data=G:/AI/Dataset/Pose Counting Repetition.v2i.yolov8/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxmltools"
      ],
      "metadata": {
        "id": "vjUAhGwWVxJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "ade88f12-1fae-4853-9456-d3c215abef77"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxmltools\n",
            "  Downloading onnxmltools-1.13.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnxmltools) (2.0.2)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxmltools) (1.17.0)\n",
            "Collecting onnxconverter-common (from onnxmltools)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxmltools) (5.29.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxconverter-common->onnxmltools) (24.2)\n",
            "Collecting protobuf>=3.20.2 (from onnx->onnxmltools)\n",
            "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading onnxmltools-1.13.0-py2.py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.0/329.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnxconverter-common, onnxmltools\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnxconverter-common-1.14.0 onnxmltools-1.13.0 protobuf-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2fb69e9244f4475790f2fa5351c6a498"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxmltools.utils.float16_converter import convert_float_to_float16\n",
        "import onnx\n",
        "\n",
        "model_fp32 = onnx.load(\"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_s11.onnx\")\n",
        "model_fp16 = convert_float_to_float16(model_fp32)\n",
        "onnx.save(model_fp16, \"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_pruned_fp16_s11.onnx\")\n"
      ],
      "metadata": {
        "id": "N790Blb8WiBd"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx onnxruntime onnxruntime-tools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd3U3YckODVH",
        "outputId": "5d63aedb-7f47-4893-8c90-2bc4fa7f8521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnxruntime-tools\n",
            "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (9.0.0)\n",
            "Collecting py3nvml (from onnxruntime-tools)\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting xmltodict (from py3nvml->onnxruntime-tools)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict, onnx, humanfriendly, py3nvml, coloredlogs, onnxruntime-tools, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.21.1 onnxruntime-tools-1.7.0 py3nvml-0.2.7 xmltodict-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-tool"
      ],
      "metadata": {
        "id": "8uJ8qWoBWpM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fab870b-0514-4f06-9c96-a7f0ea59ebef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx-tool\n",
            "  Downloading onnx_tool-0.9.0-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting onnx (from onnx-tool)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnx-tool) (2.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from onnx-tool) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->onnx-tool) (5.29.4)\n",
            "Downloading onnx_tool-0.9.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnx-tool\n",
            "Successfully installed onnx-1.17.0 onnx-tool-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parameter count"
      ],
      "metadata": {
        "id": "zD6zDKtA6TCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx_opcounter"
      ],
      "metadata": {
        "id": "8Nnal2u8YJex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "id": "q60ynRpX6X-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/S25-ECE556-ODDL/yolo_code/models/best_s11.pt\"\n",
        "yolo = YOLO(model_path)\n",
        "net = yolo.model\n",
        "net.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 640, 640)  # Adjust to your model's input size\n",
        "flops = FlopCountAnalysis(net, dummy_input)\n",
        "print(\"Total MACs:\", flops.total() / 1e6, \"MMACs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jCd8Gr_fjEK",
        "outputId": "f1825752-fd41-4c23-e0c5-41992cc40d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::silu_ encountered 83 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 24 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 10 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::softmax encountered 2 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::meshgrid encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sub encountered 4 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::div encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 2 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::clone encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MACs: 11787.5352 MMACs\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "collapsed_sections": [
        "dXhTckbEdLL4"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}